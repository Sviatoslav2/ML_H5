{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_load\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import data_plot\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1_test, target1_train = data_load.target3_test, data_load.target3_train\n",
    "\n",
    "target1_test = shuffle(target1_test)\n",
    "target1_train = shuffle(target1_train)\n",
    "\n",
    "target1_test[target1_test.columns] = target1_test[target1_test.columns].apply(pd.to_numeric, errors='coerce')\n",
    "target1_train[target1_train.columns] = target1_train[target1_train.columns].apply(pd.to_numeric, errors='coerce')\n",
    "#print(target1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([target1_test, target1_train],ignore_index=True)\n",
    "predictors = data.columns.drop(['Outcome'])\n",
    "\n",
    "#data_plot.tsne_plot2d(data[predictors], data['Outcome'])\n",
    "#data_plot.tsne_plot3d(data[predictors], data['Outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_plot.pca_plot3d(data[predictors], data['Outcome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce Dimensionality. Use PCA or SVD of MDA. In general, MDA is better for separation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998545597437\n",
      "Common explained variance ratio: 99.85%\n",
      "=> Number of pc is 3\n"
     ]
    }
   ],
   "source": [
    "pca = data_plot.pca_explained_variance_ratio(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms for 2 classes and how they are distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(3):\n",
    "#    data_plot.histo_drawer(pca[target1_train[target1_train['Outcome'] == 0].index, i], \"Inactive samples\", i)\n",
    "#    data_plot.histo_drawer(pca[target1_train[target1_train['Outcome'] == 1].index, i], \"Active samples\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model report ############################################### !\n",
      "Accuracy on train ==  0.98773006135\n",
      "f1_score_train ==  0.60801923832\n",
      "ROC on train ==  0.5625\n",
      "AUC on train ==  nan\n",
      "############################################################ !\n",
      "Accuracy on test ==  0.98773006135\n",
      "f1_score on test ==  0.496174220129\n",
      "ROC on test ==  0.5625\n",
      "AUC on test ==  nan\n",
      "End of model report ######################################## !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "import model_plot\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model1 = KNeighborsClassifier(n_neighbors=2)\n",
    "predicts = data.columns.drop(['Outcome'])\n",
    "model1, lst = model_plot.modelfit_for_classification(model1, target1_train[predictors], target1_test[predictors], target1_train['Outcome'], target1_test['Outcome'],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model report ############################################### !\n",
      "Accuracy on train ==  0.264680105171\n",
      "f1_score_train ==  0.221062815454\n",
      "ROC on train ==  0.627111111111\n",
      "AUC on train ==  nan\n",
      "############################################################ !\n",
      "Accuracy on test ==  0.264680105171\n",
      "f1_score on test ==  0.208600592103\n",
      "ROC on test ==  0.627111111111\n",
      "AUC on test ==  nan\n",
      "End of model report ######################################## !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf1 = GaussianNB()\n",
    "model1, lst = model_plot.modelfit_for_classification(clf1, target1_train[predictors], target1_test[predictors], target1_train['Outcome'], target1_test['Outcome'],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model report ############################################### !\n",
      "Accuracy on train ==  0.986561495764\n",
      "f1_score_train ==  0.536615656268\n",
      "ROC on train ==  0.520833333333\n",
      "AUC on train ==  nan\n",
      "############################################################ !\n",
      "Accuracy on test ==  0.986561495764\n",
      "f1_score on test ==  0.496470588235\n",
      "ROC on test ==  0.520833333333\n",
      "AUC on test ==  nan\n",
      "End of model report ######################################## !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf2 = RandomForestClassifier(n_estimators=1000,random_state=0, max_depth=6,min_samples_leaf=2,max_features='sqrt')\n",
    "model1, lst = model_plot.modelfit_for_classification(clf2, target1_train[predictors], target1_test[predictors], target1_train['Outcome'], target1_test['Outcome'],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model report ############################################### !\n",
      "Accuracy on train ==  1.0\n",
      "f1_score_train ==  1.0\n",
      "ROC on train ==  1.0\n",
      "AUC on train ==  nan\n",
      "############################################################ !\n",
      "Accuracy on test ==  1.0\n",
      "f1_score on test ==  0.542001070091\n",
      "ROC on test ==  1.0\n",
      "AUC on test ==  nan\n",
      "End of model report ######################################## !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf3 = GradientBoostingClassifier(max_depth=1000, n_estimators=1000,learning_rate=1.0, random_state=0)\n",
    "model1, lst = model_plot.modelfit_for_classification(clf3, target1_train[predictors], target1_test[predictors], target1_train['Outcome'], target1_test['Outcome'],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 1000,\n",
    "    'warm_start': True, \n",
    "    #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "kn_params = {'n_neighbors' : 2}\n",
    "\n",
    "GradientBoostingClassifier_params = {'n_estimators':1000, 'learning_rate' : 0.5,\n",
    "                                     'max_features':2, 'max_depth' : 1000,\n",
    "                                     'random_state' : 0}\n",
    "\n",
    "GaussianNB_params = {}\n",
    "\n",
    "SVC_params = {'kernel' : 'rbf'}\n",
    "\n",
    "\n",
    "lst_of_models=[RandomForestClassifier, KNeighborsClassifier, GaussianNB, GradientBoostingClassifier, svm.SVC]\n",
    "lst_of_models_names = [\"RandomForestClassifier\", \"KNeighborsClassifier\", \"GaussianNB\", \"GradientBoostingClassifier\", \"SVC\"]\n",
    "lst_of_dct_params=[rf_params, kn_params, GaussianNB_params,GradientBoostingClassifier_params, SVC_params]\n",
    "\n",
    "\n",
    "import KFold_for_combining_base_learning_models\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "ntrain = target1_train[predictors].shape[0]\n",
    "ntest = target1_test['Outcome'].shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "kf_split = KFold(n_splits=NFOLDS, random_state=None, shuffle=False)\n",
    "\n",
    "lst_of_models=[RandomForestClassifier, KNeighborsClassifier, GaussianNB, GradientBoostingClassifier, svm.SVC]\n",
    "lst_of_models_names = [\"RandomForestClassifier\", \"KNeighborsClassifier\", \"GaussianNB\", \"GradientBoostingClassifier\", \"SVC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import model_plot\n",
    "\n",
    "gbm = xgb.XGBClassifier(\n",
    "    learning_rate = 0.002,\n",
    "    n_estimators= 2000,\n",
    "    max_depth= 4,\n",
    "    min_child_weight= 2,\n",
    "    gamma=1,\n",
    "    #gamma=0.9,                        \n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread= -1,\n",
    "    scale_pos_weight=1)\n",
    "\n",
    "#model_gbm, lst = model_plot.modelfit_for_classification(gbm, x_train,x_test, target1_train['Outcome'], target1_test['Outcome'],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def cnf_matrix_fo_prediction(data,pred,target):\n",
    "    cnf_matrix=confusion_matrix(data[target].values,pred)\n",
    "    print(\"TP == \",cnf_matrix[1,1,])#\n",
    "    print(\"TN == \",cnf_matrix[0,0])\n",
    "    print(\"FP == \",cnf_matrix[0,1])\n",
    "    print(\"FN == \",cnf_matrix[1,0])    \n",
    "    \n",
    "def show_data_imbalance(data, target):\n",
    "    Count_Normal_zero = len(data.loc[data[target] == 0])\n",
    "    Count_Normal_one = len(data.loc[data[target] == 1])\n",
    "    \n",
    "    print(\"Total number 0 == \", Count_Normal_zero)\n",
    "    print(\"Total number 1 == \", Count_Normal_one)\n",
    "    \n",
    "    Percentage_of_zero = Count_Normal_zero/(Count_Normal_zero + Count_Normal_one)\n",
    "    print(\"percentage of normal transacation is \",Percentage_of_zero * 100)\n",
    "    Percentage_of_one= Count_Normal_one/(Count_Normal_zero + Count_Normal_one)\n",
    "    print(\"percentage of fraud transacation \",Percentage_of_one * 100)\n",
    "\n",
    "    \n",
    "\n",
    "def undersample(x, y, x_active=None, y_active=None, times=1):\n",
    "    if x_active is None and y_active is None:\n",
    "        x_active = x[y == 1]\n",
    "        y_active = y[y == 1]\n",
    "    inactive_indices= np.array(x[y == 0].index)\n",
    "    count_active = len(y_active)\n",
    "    inactive_indices_undersample = np.array(np.random.choice(inactive_indices,(times*count_active),replace=False))\n",
    "    \n",
    "    undersample_data_x = pd.concat([x.loc[inactive_indices_undersample,:], x_active])\n",
    "    undersample_data_y = pd.concat([y.loc[inactive_indices_undersample], y_active])\n",
    "    return undersample_data_x, undersample_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KFold_for_combining_base_learning_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-08c32cf8cd7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mKFold_for_combining_first_level\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold_for_combining_base_learning_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKFold_for_combining_first_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst_of_models_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlst_of_models\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlst_of_dct_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget1_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget1_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Outcome'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkf_split\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mx_train_stacked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test_stacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold_for_combining_first_level\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_test_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KFold_for_combining_base_learning_models' is not defined"
     ]
    }
   ],
   "source": [
    "x_train, y_train = target1_train[predictors], target1_train['Outcome']\n",
    "x_test, y_test = target1_test[predictors], target1_test['Outcome']\n",
    "\n",
    "\n",
    "KFold_for_combining_first_level = KFold_for_combining_base_learning_models.KFold_for_combining_first_level(lst_of_models_names,lst_of_models,lst_of_dct_params,target1_train,target1_test,'Outcome',kf_split)\n",
    "x_train_stacked, x_test_stacked = KFold_for_combining_first_level.get_test_train(ntrain, ntest,4)\n",
    "\n",
    "\n",
    "\n",
    "model_gbm, lst = model_plot.modelfit_for_classification(gbm, x_train_stacked,x_test_stacked,y_train,y_test,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
