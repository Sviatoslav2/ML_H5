{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_load\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import data_plot\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1_test, target1_train = data_load.target2_test, data_load.target2_train\n",
    "\n",
    "target1_test = shuffle(target1_test)\n",
    "target1_train = shuffle(target1_train)\n",
    "\n",
    "target1_test[target1_test.columns] = target1_test[target1_test.columns].apply(pd.to_numeric, errors='coerce')\n",
    "target1_train[target1_train.columns] = target1_train[target1_train.columns].apply(pd.to_numeric, errors='coerce')\n",
    "#print(target1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([target1_test, target1_train],ignore_index=True)\n",
    "predictors = data.columns.drop(['Outcome'])\n",
    "\n",
    "#data_plot.tsne_plot2d(data[predictors], data['Outcome'])\n",
    "#data_plot.tsne_plot3d(data[predictors], data['Outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_plot.pca_plot3d(data[predictors], data['Outcome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce Dimensionality. Use PCA or SVD of MDA. In general, MDA is better for separation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998480842672\n",
      "Common explained variance ratio: 99.85%\n",
      "=> Number of pc is 3\n"
     ]
    }
   ],
   "source": [
    "pca = data_plot.pca_explained_variance_ratio(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms for 2 classes and how they are distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(3):\n",
    "#    data_plot.histo_drawer(pca[target1_train[target1_train['Outcome'] == 0].index, i], \"Inactive samples\", i)\n",
    "#    data_plot.histo_drawer(pca[target1_train[target1_train['Outcome'] == 1].index, i], \"Active samples\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model report ############################################### !\n",
      "Accuracy on train ==  0.996717609918\n",
      "f1_score_train ==  0.570216081046\n",
      "ROC on train ==  0.538235294118\n",
      "AUC on train ==  nan\n",
      "############################################################ !\n",
      "Accuracy on test ==  0.996717609918\n",
      "f1_score on test ==  0.499057354728\n",
      "ROC on test ==  0.538235294118\n",
      "AUC on test ==  nan\n",
      "End of model report ######################################## !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning:\n",
      "\n",
      "No positive samples in y_true, true positive value should be meaningless\n",
      "\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning:\n",
      "\n",
      "No positive samples in y_true, true positive value should be meaningless\n",
      "\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning:\n",
      "\n",
      "No positive samples in y_true, true positive value should be meaningless\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import model_plot\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model1 = KNeighborsClassifier(n_neighbors=2)\n",
    "predicts = data.columns.drop(['Outcome'])\n",
    "model1, lst = model_plot.modelfit_for_classification(model1, target1_train[predictors], target1_test[predictors], target1_train['Outcome'], target1_test['Outcome'],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model report ############################################### !\n",
      "Accuracy on train ==  0.138592126445\n",
      "f1_score_train ==  0.123438141998\n",
      "ROC on train ==  0.567759803613\n",
      "AUC on train ==  nan\n",
      "############################################################ !\n",
      "Accuracy on test ==  0.138592126445\n",
      "f1_score on test == "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning:\n",
      "\n",
      "No positive samples in y_true, true positive value should be meaningless\n",
      "\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning:\n",
      "\n",
      "No positive samples in y_true, true positive value should be meaningless\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.121007221212\n",
      "ROC on test ==  0.567759803613\n",
      "AUC on test ==  nan\n",
      "End of model report ######################################## !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning:\n",
      "\n",
      "No positive samples in y_true, true positive value should be meaningless\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf1 = GaussianNB()\n",
    "model1, lst = model_plot.modelfit_for_classification(clf1, target1_train[predictors], target1_test[predictors], target1_train['Outcome'], target1_test['Outcome'],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model report ############################################### !\n",
      "Accuracy on train ==  0.996445819657\n",
      "f1_score_train ==  0.499109873078\n",
      "ROC on train ==  None\n",
      "AUC on train ==  None\n",
      "############################################################ !\n",
      "Accuracy on test ==  0.996445819657\n",
      "f1_score on test ==  0.499120308311\n",
      "ROC on test ==  None\n",
      "AUC on test ==  None\n",
      "End of model report ######################################## !\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf2 = RandomForestClassifier(n_estimators=1000,random_state=0, max_depth=6,min_samples_leaf=2,max_features='sqrt')\n",
    "model1, lst = model_plot.modelfit_for_classification(clf2, target1_train[predictors], target1_test[predictors], target1_train['Outcome'], target1_test['Outcome'],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model report ############################################### !\n",
      "Accuracy on train ==  1.0\n",
      "f1_score_train ==  1.0\n",
      "ROC on train ==  1.0\n",
      "AUC on train ==  nan\n",
      "############################################################ !\n",
      "Accuracy on test ==  1.0\n",
      "f1_score on test ==  0.550277976041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning:\n",
      "\n",
      "No positive samples in y_true, true positive value should be meaningless\n",
      "\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning:\n",
      "\n",
      "No positive samples in y_true, true positive value should be meaningless\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC on test ==  1.0\n",
      "AUC on test ==  nan\n",
      "End of model report ######################################## !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:656: UndefinedMetricWarning:\n",
      "\n",
      "No positive samples in y_true, true positive value should be meaningless\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf3 = GradientBoostingClassifier(max_depth=1000, n_estimators=1000,learning_rate=1.0, random_state=0)\n",
    "model1, lst = model_plot.modelfit_for_classification(clf3, target1_train[predictors], target1_test[predictors], target1_train['Outcome'], target1_test['Outcome'],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 1000,\n",
    "    'warm_start': True, \n",
    "    #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "kn_params = {'n_neighbors' : 2}\n",
    "\n",
    "GradientBoostingClassifier_params = {'n_estimators':1000, 'learning_rate' : 0.5,\n",
    "                                     'max_features':2, 'max_depth' : 1000,\n",
    "                                     'random_state' : 0}\n",
    "\n",
    "GaussianNB_params = {}\n",
    "\n",
    "SVC_params = {'kernel' : 'rbf'}\n",
    "\n",
    "\n",
    "lst_of_models=[RandomForestClassifier, KNeighborsClassifier, GaussianNB, GradientBoostingClassifier, svm.SVC]\n",
    "lst_of_models_names = [\"RandomForestClassifier\", \"KNeighborsClassifier\", \"GaussianNB\", \"GradientBoostingClassifier\", \"SVC\"]\n",
    "lst_of_dct_params=[rf_params, kn_params, GaussianNB_params,GradientBoostingClassifier_params, SVC_params]\n",
    "\n",
    "\n",
    "import KFold_for_combining_base_learning_models\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "ntrain = target1_train[predictors].shape[0]\n",
    "ntest = target1_test['Outcome'].shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "kf_split = KFold(n_splits=NFOLDS, random_state=None, shuffle=False)\n",
    "\n",
    "lst_of_models=[RandomForestClassifier, KNeighborsClassifier, GaussianNB, GradientBoostingClassifier, svm.SVC]\n",
    "lst_of_models_names = [\"RandomForestClassifier\", \"KNeighborsClassifier\", \"GaussianNB\", \"GradientBoostingClassifier\", \"SVC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import model_plot\n",
    "\n",
    "gbm = xgb.XGBClassifier(\n",
    "    learning_rate = 0.002,\n",
    "    n_estimators= 2000,\n",
    "    max_depth= 4,\n",
    "    min_child_weight= 2,\n",
    "    gamma=1,\n",
    "    #gamma=0.9,                        \n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread= -1,\n",
    "    scale_pos_weight=1)\n",
    "\n",
    "#model_gbm, lst = model_plot.modelfit_for_classification(gbm, x_train,x_test, target1_train['Outcome'], target1_test['Outcome'],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def cnf_matrix_fo_prediction(data,pred,target):\n",
    "    cnf_matrix=confusion_matrix(data[target].values,pred)\n",
    "    print(\"TP == \",cnf_matrix[1,1,])#\n",
    "    print(\"TN == \",cnf_matrix[0,0])\n",
    "    print(\"FP == \",cnf_matrix[0,1])\n",
    "    print(\"FN == \",cnf_matrix[1,0])    \n",
    "    \n",
    "def show_data_imbalance(data, target):\n",
    "    Count_Normal_zero = len(data.loc[data[target] == 0])\n",
    "    Count_Normal_one = len(data.loc[data[target] == 1])\n",
    "    \n",
    "    print(\"Total number 0 == \", Count_Normal_zero)\n",
    "    print(\"Total number 1 == \", Count_Normal_one)\n",
    "    \n",
    "    Percentage_of_zero = Count_Normal_zero/(Count_Normal_zero + Count_Normal_one)\n",
    "    print(\"percentage of normal transacation is \",Percentage_of_zero * 100)\n",
    "    Percentage_of_one= Count_Normal_one/(Count_Normal_zero + Count_Normal_one)\n",
    "    print(\"percentage of fraud transacation \",Percentage_of_one * 100)\n",
    "\n",
    "    \n",
    "\n",
    "def undersample(x, y, x_active=None, y_active=None, times=1):\n",
    "    if x_active is None and y_active is None:\n",
    "        x_active = x[y == 1]\n",
    "        y_active = y[y == 1]\n",
    "    inactive_indices= np.array(x[y == 0].index)\n",
    "    count_active = len(y_active)\n",
    "    inactive_indices_undersample = np.array(np.random.choice(inactive_indices,(times*count_active),replace=False))\n",
    "    \n",
    "    undersample_data_x = pd.concat([x.loc[inactive_indices_undersample,:], x_active])\n",
    "    undersample_data_y = pd.concat([y.loc[inactive_indices_undersample], y_active])\n",
    "    return undersample_data_x, undersample_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:308: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:308: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:308: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:308: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model report ############################################### !\n",
      "Accuracy on train ==  0.996445819657\n",
      "f1_score_train ==  0.499109873078\n",
      "ROC on train ==  None\n",
      "AUC on train ==  None\n",
      "############################################################ !\n",
      "Accuracy on test ==  0.996445819657\n",
      "f1_score on test ==  0.499120308311\n",
      "ROC on test ==  None\n",
      "AUC on test ==  None\n",
      "End of model report ######################################## !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = target1_train[predictors], target1_train['Outcome']\n",
    "x_test, y_test = target1_test[predictors], target1_test['Outcome']\n",
    "\n",
    "\n",
    "KFold_for_combining_first_level = KFold_for_combining_base_learning_models.KFold_for_combining_first_level(lst_of_models_names,lst_of_models,lst_of_dct_params,target1_train,target1_test,'Outcome',kf_split)\n",
    "x_train_stacked, x_test_stacked = KFold_for_combining_first_level.get_test_train(ntrain, ntest,2)\n",
    "\n",
    "\n",
    "\n",
    "model_gbm, lst = model_plot.modelfit_for_classification(gbm, x_train_stacked,x_test_stacked,y_train,y_test,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
